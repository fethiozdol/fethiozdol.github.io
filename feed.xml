<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://fethiozdol.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://fethiozdol.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-01T21:12:52+00:00</updated><id>https://fethiozdol.github.io/feed.xml</id><title type="html">This is My Pattern</title><subtitle>Hi, I&apos;m Fethi. I&apos;m an AWS solutions architect, and This is My Pattern. </subtitle><entry><title type="html">How-to Startup with DevOps from Day 0 – Part 1</title><link href="https://fethiozdol.github.io/blog/2024/ht-startup-w-devops-p01/" rel="alternate" type="text/html" title="How-to Startup with DevOps from Day 0 – Part 1"/><published>2024-07-01T00:00:00+00:00</published><updated>2024-07-01T00:00:00+00:00</updated><id>https://fethiozdol.github.io/blog/2024/ht-startup-w-devops-p01</id><content type="html" xml:base="https://fethiozdol.github.io/blog/2024/ht-startup-w-devops-p01/"><![CDATA[<h1 id="foreword">Foreword</h1> <p>Perhaps it’s the banking industry in which I started my IT career, but I’ve been obsessed with high speed and high quality software delivery ever since I took up platform engineering activities.</p> <p>Like at any startup, there are few people writing code, and it may be OK for some to leave software delivery disorganized. Not for us.</p> <p>We build multiple SaaS for businesses at <a href="https://www.xecuta.co.uk">Xecuta</a> and it was obvious from day 0 that we had to set our solid architecture principles.</p> <p>It may be our early days, but our architecture principles have already given us the confidence in managing AWS resources effectively.</p> <p>In the first part of this series, I’ll talk about our architecture principles and our design thinking which led us to organize our AWS environments and choose tools and services.</p> <h2 id="xecutas-architecture-principles">Xecuta’s Architecture Principles</h2> <p>Here’s our 10 architecture principles that we agreed before we wrote our first line of code.</p> <ol> <li>Build cloud-native and serverless architectures, because we want maximum agility and minimum OpEx from day 0 with a near-linear trajectory for OpEx:Revenue ratio at short-to-medium long term.</li> <li>Build services powered by Amazon Web Services (AWS), because they provide the best public cloud services around cloud-native and serverless architectures.</li> <li>Organize our AWS environment using AWS Organizations and adopt AWS recommended <a href="https://docs.aws.amazon.com/whitepapers/latest/organizing-your-aws-environment/basic-organization.html#basic-organization-with-infrastructure-services">Basic Organization with infrastructure services</a> pattern</li> <li>Use infrastructure-as-code for not only anything-on-cloud, but also to provision and manage</li> </ol> <ul> <li>AWS accounts</li> <li>Git repositories</li> <li>CI/CD pipelines</li> </ul> <ol> <li>Security from day 0 <ul> <li>Use SSO to access anything</li> <li>Use free or low-cost security services where possible</li> </ul> </li> <li>Use Open Source Software from day 0</li> <li>KISS (Keept It Simple, Stupid)</li> <li>Adopt <a href="https://12factor.net/">The Twelve-Factor App</a> methodology</li> <li>Continuous Delivery from day 0 <ul> <li>Use Static Code Analysis from day 0</li> <li>Adopt <a href="https://trunkbaseddevelopment.com/">trunk-based development</a> with branch-to-release strategy</li> <li>Multi git-repo strategy with isolated and independent CI/CD pipelines</li> <li>Re-build and re-deploy untouched code every 3 months</li> </ul> </li> <li>Build once deploy many with immutable build artefacts <ul> <li>Use conventional commits at all times</li> <li>Use automation for semantic versioning and generating CHANGELOG</li> <li>Use package managers like npm or pip to manage code dependencies</li> </ul> </li> </ol> <blockquote> <p>Re: #3: You may want to look at <a href="https://docs.aws.amazon.com/whitepapers/latest/organizing-your-aws-environment/basic-organization.html#basic-organization-with-cicd-as-a-separate-function">Basic organization with CI/CD as a separate function</a> as well, but we decided to make Infrastructure OU enclose Deployments OU for simplicity.</p> </blockquote> <h2 id="how-its-going-so-far">How it’s going so far</h2> <p>At the time of writing, Xecuta has:</p> <ul> <li>15 AWS Accounts</li> <li>30+ Git repositories, which also means <ul> <li>30+ Build jobs</li> <li>30+ CI/CD pipelines</li> <li>30+ On-Demand Deploy pipelines</li> </ul> </li> <li>2 separate multi-tenant SaaS offerings <ul> <li>3 environments for each</li> <li>Multiple SaaS customers for each</li> </ul> </li> <li>Code Quality from day 0 <ul> <li>Static Code Analysis with at least 80% Code Coverage, we pay €11/month</li> <li>OSS Vulnerabilities and OWASP 10 security scanning</li> <li>Policy-as-code for infrastructure-as-code</li> </ul> </li> <li>7,000+ lines of all code</li> </ul> <blockquote> <p>We are just 1 full-time and 1 part-time developers <br/> AND AWS bill for <strong>non-workload OUs</strong> last month was only <strong>$19.90</strong></p> </blockquote> <hr/> <h2 id="plan-from-day-0">Plan from Day 0</h2> <p>First, let’s talk about how we organize our AWS accounts and resources.</p> <p>Assume we have a single AWS account, which becomes our AWS Organizations management account and we configure our IAM Identity Center to enable SSO.</p> <p>With respect to our principles #3 and #4, we want all organization OUs and member accounts to be managed by infrastructure-as-code.</p> <p>For this purpose, we have 2 single infrastructure-as-code Git repositories:</p> <ul> <li>AWS Accounts Management</li> <li>Git repositories Management</li> </ul> <p>Our system administrators should be able to apply infrastructure-as-code changes from their local workstations, which will be authorized by temporary credentials issued by SSO (IAM Identity Center).</p> <pre><code class="language-mermaid">flowchart TD
  A["Git Repositories Management"]:::mgmt
  B["AWS Accounts Management"]:::mgmt
 subgraph Projects ["Projects"]
    subgraph SharedServices
        Projects_A["Shared Services"]:::ss
    end
    subgraph Workloads
        direction LR
        Projects_B["SaaS 1"]:::wl
        Projects_C["SaaS 2"]:::wl
        Projects_D["Core Service 1"]:::wl
    end
  end
  A -- manage Git repo, branch policies, pipelines etc. --&gt; Projects
  B -- manage OUs, SCP, permission sets, member accounts etc. --&gt; Projects
  classDef ss fill:#33cc33, stroke:#303;
  classDef wl fill:#ff3399, color: #fff, stroke:#303;
  classDef mgmt fill:#aa0000, color: #fff;
</code></pre> <p>I leave “Shared Services” to Part 2 of the series, as I plan to get into a lower level with more code.</p> <p>For the time being, let’s assume we have a Shared Services account, it has the basic architecture set up and it provides some level of build and deployment capabilities.</p> <hr/> <h2 id="workload-infra-base">Workload Infra Base</h2> <p>Our design thinking on how we should organize our AWS resources led us to several questions, such as:</p> <ul> <li>If a KMS key is used to encrypt and decrypt messages across all SQS queues in an AWS account, where should the key be maintained and who should maintain it</li> <li>There may be some AWS services like VPCs that our developers can be hands-off and we may want to restrict their maintenance to a smaller set of people, such as DevOps engineers only</li> <li>We must avoid cyclic dependencies and how can we control this in an ecosystem with many microservices</li> <li>We may want to keep the number of dependencies between microservices at a minimum so they continue to be easily disposable</li> </ul> <p><strong>Workload Infra Base</strong> is our answer to this problem.</p> <p>A workload can be either a SaaS or a core service. A core service, such as CRM or Invoicing, is part of the company’s platform, which serves all SaaS offered by the company.</p> <p>A component represents a microservice, or a miniservice, in which we manage only the <strong>compute</strong> resources, gateways and event mappings. Anything else is managed in Workload Infra Base, which can be one or more infrastructure-as-code repositories.</p> <p>For example, if we think of a typical AWS serverless application:</p> <ul> <li>Infra Base manages Route 53 zone, ACM certificate, KMS key, all IAM roles including Lambda function execution roles, DynamoDB tables, SQS queues, S3 buckets, EventBridge Bus, Pipe etc</li> <li>The component manages the API Gateway and Lambda function. It imports / references ARNs of IAM roles, DynamoDB tables, SQS queues, S3 buckets etc. so it can define event mappings and add IAM policies for its implicit resources to access the <em>referenced</em> AWS resources</li> </ul> <pre><code class="language-mermaid">flowchart TD
 subgraph subGraph0["Workload 1"]
    direction BT
        A["Infra Base"]:::base
        B["Component 1"]:::cmp
        C["Component 2"]:::cmp
        D["Component 3"]:::cmp
  end
    B -. imports from .-&gt; A
    C -. imports from .-&gt; A
    D -. imports from .-&gt; A
classDef base fill:#f96, stroke:#303;
classDef cmp color:#fff, fill:#b509ac, stroke:#303;
</code></pre> <p>Assume we have a CRM system, in which Customer Service exposes an API for our web apps as well as backends of SaaS applications to get customer details. Hence, we want our Components to import resources from other components, even from those outside their own workloads, too.</p> <p>In another scenario, we may want to have a centralised Email microservice in our Core Services, and we’d like it to use SES identity domain, which is environment-agnostic therefore managed outside our workloads, in our Shared Services.</p> <p>In short, resources can be both intra-workload and inter-workload dependencies.</p> <pre><code class="language-mermaid">flowchart TD
 subgraph SGA2["Shared Services"]
    C["Shared Services Infra Base"]:::base
  end
 subgraph SGA3["SaaS 1"]
    direction LR
    D["SaaS 1 Infra Base"]:::base
    E["SaaS 1 Component 1"]:::cmp-. imports from .-&gt; D
    F["SaaS 1 Component 2"]:::cmp-. imports from .-&gt; D
    G["SaaS 1 Component 3"]:::cmp-. imports from .-&gt; D
  end
 subgraph SGA4["Core Services"]
    M["Core Services Infra Base"]:::base
    N["Email Service"]:::cmp-. imports from .-&gt; M
  end
 subgraph SGA5["CRM"]
    K["CRM Infra Base"]:::base
    L["Customer Service"]:::cmp-. imports from .-&gt; K
  end
    E -. imports from .-&gt; G &amp; L
    F -. imports from .-&gt; N
    N -. imports from .-&gt; C
classDef base fill:#f96, stroke:#303;
classDef cmp color:#fff, fill:#b509ac, stroke:#303;
</code></pre> <hr/> <h2 id="inter-workload-and-intra-workload-resource-dependencies">Inter-Workload and Intra-Workload Resource Dependencies</h2> <p>Terraform has quickly become the de-facto in infrastructure-as-code but it does not fill the gap between <em>infrastructure</em> and <em>application code</em>, and that’s expected, because it’s not designed for software development.</p> <p>We can use AWS CDK as the singular approach to implement the infra base and components. Since AWS CDK creates CloudFormation stacks, it is possible to import &amp; export resources between CloudFormation stacks, exporting from infra base’s stacks and importing into components’ stacks.</p> <p>Whilst this approach has its many pros, there are some important drawbacks of using AWS CDK from our perspective:</p> <ol> <li>Import &amp; Export functionality in CloudFormation creates physical dependencies between CloudFormation stacks, and this may cause human interventions during major refactoring activities. Imagine logging into prod environment and deleting CloudFormation stacks manually. That’s not going to work for us.</li> <li>Cloud Development Kits like AWS CDK have brought the power of programming languages into infrastructure-as-code, enabling full stack engineering and rapid software development. Enterprises can produce reusable and modular CDK modules as <code class="language-plaintext highlighter-rouge">npm</code>, <code class="language-plaintext highlighter-rouge">pip</code>, or <code class="language-plaintext highlighter-rouge">go</code> packages, but there aren’t many reusable CDK modules available in the wider community, whereas there are many production-ready modules available in Terraform today.</li> <li>This is my personal opinion and I’m sure many of you will disagree with this, but Id don’t buy into using programming languages for infrastructure-as-code. Although I’ve been using AWS CDK for my other projects lately, I’m still an advocate of using more limited and strict languages like YAML for infrastructure-as-code. I believe “The best code is no code at all” is true for infrastructure-as-code. Even the simplest programming language brings some complexity overhead; you need more knowledge to write good code in a programming language and you also need to perform maintenance for runtime environment upgrades. With HCL or YAML, there is not much of a major room for any runtime upgrades or weird runtime errors or any unintended behaviours.</li> </ol> <p>Third is a personal opinion. We could have lived with the first drawback, but the second one is the deal breaker. We’re quite limited on resources (people and time); we can’t maintain 1000s of lines of infrastructure-as-code to reinvent the wheel.</p> <p>An alternative could be “CDK for Terraform”, but we are not comfortable with living on the cutting edge; as CDKTF “may still have breaking changes before its 1.0 release”.</p> <p>We could also look into <a href="https://www.pulumi.com/docs/concepts/vs/terraform/">Pulumi</a>. Its features appear to be very promising, but Terraform’s de-facto position within the wider community, was the tiebreaker for us. Limitless reusable modules, and not to mention our existing Terraform knowledge.</p> <hr/> <p>Obviously, Terraform would not be good enough on its own for software development and testing on our local workstations, so we started experimenting with a hybrid-solution to get the best out of two different worlds:</p> <ul> <li>We use Terraform to build and manage our workloads’ infra base</li> <li>We use AWS SAM to <strong>build and package but <em>not to deploy</em></strong> our serverless applications</li> <li>We wrap SAM projects into isolated Terraform states, which have only one Terraform resource, and that is an <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudformation_stack"><code class="language-plaintext highlighter-rouge">aws_cloudformation_stack</code></a></li> <li>We use <a href="https://developer.hashicorp.com/terraform/language/state/remote-state-data"><code class="language-plaintext highlighter-rouge">terraform_remote_state</code></a> to access workload infra base outputs and pass their values to the underlying CloudFormation stack through CloudFormation parameters</li> </ul> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01-480.webp 480w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01-800.webp 800w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02-480.webp 480w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02-800.webp 800w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <div class="caption"> Swipe left to see how our pipelines work in our hybrid solution. </div> <p>Thanks to trunk based development, strict conventional commits and automated semantic versioning, our builds produce immutable builds that we build once and deploy many. CD pipelines understand the target environment from the artefact version and perform Terraform plan &amp; apply, which actually does CloudFormation stack create/update in the background.</p> <p>Finally, if the Workload Infra Base gets very big, we can split into 2 or more repositories and orchestrate their deployments using <a href="https://terragrunt.gruntwork.io/">Terragrunt</a>.</p> <p>We were quite happy with our experiment and decided to follow this pattern in building SaaS at Xecuta. I understand our approach may seem too complex or unnecessary for some, but again, best out of two worlds!</p> <ul> <li>Thanks to Terraform, we are able to reuse terraform modules produced by the community and this keep LoC of our infrastructure-as-code low</li> <li>Thanks to AWS SAM, we can develop and test locally</li> <li>And we can manage inter-workload and intra-workload dependencies in a consistent and reliable manner</li> </ul> <p>I hope you enjoyed my first blog post about Workload Infra Base pattern with hybrid implementation using AWs SAM and Terraform.</p> <p>Part 2 of this series will continue with which SCM and Orchestration tool(s) we opted to use and how we built our Shared Services initially. Until then, ciao!</p>]]></content><author><name></name></author><category term="startup"/><category term="devops"/><category term="day0"/><category term="aws"/><category term="terraform"/><category term="cdk"/><category term="aws-cdk"/><summary type="html"><![CDATA[This blog series aim to stop you delaying DevOps for your new startup. In the first section, I'm going to talk about which DevOps services and tools we use at Xecuta and later a simple shared services account architecture that serve us in our early days.]]></summary></entry></feed>