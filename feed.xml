<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://thisismypattern.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://thisismypattern.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-02T09:28:17+00:00</updated><id>https://thisismypattern.com/feed.xml</id><title type="html">This is My Pattern</title><subtitle>Hi, I&apos;m Fethi. I&apos;m an AWS solutions architect, and This is My Pattern. </subtitle><entry><title type="html">How-to Startup with DevOps from Day 0 – Part 1</title><link href="https://thisismypattern.com/blog/2024/ht-startup-w-devops-p01/" rel="alternate" type="text/html" title="How-to Startup with DevOps from Day 0 – Part 1"/><published>2024-07-01T00:00:00+00:00</published><updated>2024-07-01T00:00:00+00:00</updated><id>https://thisismypattern.com/blog/2024/ht-startup-w-devops-p01</id><content type="html" xml:base="https://thisismypattern.com/blog/2024/ht-startup-w-devops-p01/"><![CDATA[<h1 id="foreword">Foreword</h1> <p>Perhaps it’s the banking industry in which I started my IT career, but I’ve been obsessed with high speed and high quality in software delivery ever since I took up platform engineering activities.</p> <p>We build multiple SaaS for businesses at <a href="https://www.xecuta.co.uk">Xecuta</a>. We have only few people writing code, like at any startup, but it was not OK for us to leave software delivery disorganized. It may be our early days, but our architecture principles have already given us the confidence in managing AWS resources effectively.</p> <p>In the first part of this series, I’ll talk about our architecture principles and our design thinking which led us to organize our AWS environments and choose tools and services.</p> <h2 id="xecutas-architecture-principles">Xecuta’s Architecture Principles</h2> <p>Here’s our 10 architecture principles that we agreed before we wrote first line of code.</p> <ol> <li>Build cloud-native and serverless architectures, because we want maximum agility and minimum OpEx from day 0 with a near-linear trajectory for OpEx:Revenue ratio at short-to-medium long term</li> <li>Build services powered by Amazon Web Services (AWS), because they provide the best public cloud services around cloud-native and serverless architectures</li> <li>Organize our AWS environment using AWS Organizations <ul> <li>We adopted AWS recommended <a href="https://docs.aws.amazon.com/whitepapers/latest/organizing-your-aws-environment/basic-organization.html#basic-organization-with-infrastructure-services">Basic Organization with infrastructure services</a> pattern</li> </ul> </li> <li>Use infrastructure-as-code for not only anything-on-cloud, but also to provision and manage <ul> <li>AWS accounts</li> <li>Git repositories</li> <li>CI/CD pipelines</li> </ul> </li> <li>Security from day 0 <ul> <li>Use SSO to access anything</li> <li>Use free or low-cost security services where possible</li> </ul> </li> <li>Use Open Source Software from day 0</li> <li>KISS (Keept It Simple, Stupid)</li> <li>Adopt <a href="https://12factor.net/">The Twelve-Factor App</a> methodology</li> <li>Continuous Delivery from day 0 <ul> <li>Use Static Code Analysis from day 0</li> <li>Adopt <a href="https://trunkbaseddevelopment.com/">trunk-based development</a> with branch-to-release strategy</li> <li>Multi git-repo strategy with isolated and independent CI/CD pipelines</li> <li>Re-build and re-deploy untouched code every 3 months</li> </ul> </li> <li>Build once deploy many with immutable build artefacts <ul> <li>Always use conventional commits</li> <li>Use automation for semantic versioning and generating CHANGELOG</li> <li>Use package managers like npm or pip to manage code dependencies</li> </ul> </li> </ol> <blockquote> <p>Re: principle #3: You may want to look at <a href="https://docs.aws.amazon.com/whitepapers/latest/organizing-your-aws-environment/basic-organization.html#basic-organization-with-cicd-as-a-separate-function">Basic organization with CI/CD as a separate function</a> as well, but we decided to make Infrastructure OU enclose Deployments OU for simplicity.</p> </blockquote> <h2 id="how-its-going-so-far">How it’s going so far</h2> <p>At the time of writing, Xecuta has:</p> <ul> <li>15 AWS Accounts</li> <li>30+ Git repositories, which also means <ul> <li>30+ Build jobs</li> <li>30+ CI/CD pipelines</li> <li>30+ On-Demand Deploy pipelines</li> </ul> </li> <li>2 separate multi-tenant SaaS offerings <ul> <li>3 environments for each</li> <li>Multiple SaaS customers for each</li> </ul> </li> <li>Code Quality from day 0 <ul> <li>Static Code Analysis with at least 80% Code Coverage, we pay €11/month</li> <li>OSS Vulnerabilities and OWASP 10 security scanning</li> <li>Policy-as-code for infrastructure-as-code</li> </ul> </li> <li>7,000+ lines of all code</li> </ul> <blockquote> <p>We are just 1 full-time and 1 part-time developers. <br/> AWS bill for <strong>non-workload OUs</strong> last month was only <strong>$19.90</strong>.</p> </blockquote> <hr/> <h2 id="plan-from-day-0">Plan from Day 0</h2> <p>First, let’s talk about how we organize our AWS accounts and resources.</p> <p>Assume we have a single AWS account, which becomes our AWS Organizations management account, and we configure our IAM Identity Center to enable SSO.</p> <p>With respect to our principles #3 and #4, we want all organization OUs and member accounts to be managed by infrastructure-as-code.</p> <p>We have 2 single infrastructure-as-code Git repositories for this purpose:</p> <ul> <li>AWS Accounts Management</li> <li>Git repositories Management</li> </ul> <p>Our system administrators should be able to apply infrastructure-as-code changes from their local workstations, which will be authorized by temporary credentials issued by SSO (IAM Identity Center).</p> <pre><code class="language-mermaid">flowchart TD
  A["Git Repositories Management"]:::mgmt
  B["AWS Accounts Management"]:::mgmt
 subgraph Projects ["Projects"]
    subgraph SharedServices
        Projects_A["Shared Services"]:::ss
    end
    subgraph Workloads
        direction LR
        Projects_B["SaaS 1"]:::wl
        Projects_C["SaaS 2"]:::wl
        Projects_D["Core Service 1"]:::wl
    end
  end
  A -- manage Git repo, branch policies, pipelines etc. --&gt; Projects
  B -- manage OUs, SCP, permission sets, member accounts etc. --&gt; Projects
  classDef ss fill:#33cc33, stroke:#303;
  classDef wl fill:#ff3399, color: #fff, stroke:#303;
  classDef mgmt fill:#aa0000, color: #fff;
</code></pre> <p>I leave “Shared Services” to Part 2 of the series, as I plan to get into a lower level with more code.</p> <p>For the time being, let’s assume we have a Shared Services account, it has the basic architecture set up and it provides some level of build and deployment capabilities.</p> <hr/> <h2 id="workload-infra-base">Workload Infra Base</h2> <p>Our design thinking on how we should organize our AWS resources led us to several questions, such as:</p> <ul> <li>If a KMS key is used to encrypt and decrypt messages across all SQS queues in an AWS account, where should the key be maintained and who should maintain it</li> <li>There may be some AWS services like VPCs that our developers can be hands-off, or we may want to restrict their maintenance to a smaller set of people, such as DevOps engineers only</li> <li>How can we control dependencies in an ecosystem with many microservices and avoid cyclic dependencies</li> <li>How can we keep the number of dependencies between microservices at a minimum, so they continue to be easily disposable</li> </ul> <p><strong>Workload Infra Base</strong> is our answer to this problem.</p> <p>A workload can be either a SaaS or a core service. A core service, such as CRM or Invoicing, is part of the company’s platform, which serves all SaaS offered by the company.</p> <p>A component represents a microservice, or a miniservice, in which we manage only the <strong>compute</strong> resources, gateways and event mappings. Anything else is managed in Workload Infra Base, which can be one or more infrastructure-as-code repositories.</p> <p>For example, if we think of a typical AWS serverless application:</p> <ul> <li>Infra Base manages Route 53 zone, ACM certificate, KMS key, all IAM roles including Lambda function execution roles, DynamoDB tables, SQS queues, S3 buckets, EventBridge Bus, Pipe etc</li> <li>The component manages the API Gateway and Lambda function. It imports / references ARNs of IAM roles, DynamoDB tables, SQS queues, S3 buckets etc. so it can define event mappings and add IAM policies for its implicit resources to access the <em>referenced</em> AWS resources</li> </ul> <pre><code class="language-mermaid">flowchart TD
 subgraph subGraph0["Workload 1"]
    direction BT
        A["Infra Base"]:::base
        B["Component 1"]:::cmp
        C["Component 2"]:::cmp
        D["Component 3"]:::cmp
  end
    B -. imports from .-&gt; A
    C -. imports from .-&gt; A
    D -. imports from .-&gt; A
classDef base fill:#f96, stroke:#303;
classDef cmp color:#fff, fill:#b509ac, stroke:#303;
</code></pre> <p>Assume we have a CRM system, in which Customer Service exposes an API for our web apps as well as backends of SaaS applications to get customer details. Hence, we want our Components to import resources from other components, even from those outside their own workloads, too.</p> <p>In another scenario, we may want to have a centralised Email microservice in our Core Services, and we’d like it to use SES identity domain, which is environment-agnostic therefore managed outside our workloads, in our Shared Services.</p> <p>In summary, AWS resources can be intra-workload or inter-workload dependencies, or both.</p> <pre><code class="language-mermaid">flowchart TD
 subgraph SGA2["Shared Services"]
    C["Shared Services Infra Base"]:::base
  end
 subgraph SGA3["SaaS 1"]
    direction LR
    D["SaaS 1 Infra Base"]:::base
    E["SaaS 1 Component 1"]:::cmp-. imports from .-&gt; D
    F["SaaS 1 Component 2"]:::cmp-. imports from .-&gt; D
    G["SaaS 1 Component 3"]:::cmp-. imports from .-&gt; D
  end
 subgraph SGA4["Core Services"]
    M["Core Services Infra Base"]:::base
    N["Email Service"]:::cmp-. imports from .-&gt; M
  end
 subgraph SGA5["CRM"]
    K["CRM Infra Base"]:::base
    L["Customer Service"]:::cmp-. imports from .-&gt; K
  end
    E -. imports from .-&gt; G &amp; L
    F -. imports from .-&gt; N
    N -. imports from .-&gt; C
classDef base fill:#f96, stroke:#303;
classDef cmp color:#fff, fill:#b509ac, stroke:#303;
</code></pre> <hr/> <h2 id="inter-workload-and-intra-workload-dependencies-in-infrastructure-as-code">Inter-Workload and Intra-Workload Dependencies in Infrastructure-as-Code</h2> <p>Terraform has quickly become the de-facto in infrastructure-as-code but it does not fill the gap between <em>infrastructure</em> and <em>application code</em>, and that’s expected, because it’s not designed for software development.</p> <p>We can use AWS CDK as the singular approach to implement the infra base and components. Since AWS CDK creates CloudFormation stacks, it is possible to share resources between CloudFormation stacks by exporting values from infra base’s stacks and importing them into components’ stacks.</p> <p>Whilst this approach has its many pros, there are some important drawbacks of using AWS CDK from our perspective:</p> <ol> <li>Import &amp; Export functionality in CloudFormation creates physical dependencies between CloudFormation stacks, similar to the referential integrity concept in RDBMS. CloudFormation refuses to delete the exported resources until no other CloudFormation stack imports them. This approach will cause human interventions eventually during major refactoring activities. Imagine logging into prod environment and deleting CloudFormation stacks manually. That’s not going to work for us.</li> <li>Cloud Development Kits like AWS CDK have brought the power of programming languages into infrastructure-as-code, enabling full stack engineering and rapid software development. Enterprises can produce reusable and modular CDK modules as <code class="language-plaintext highlighter-rouge">npm</code>, <code class="language-plaintext highlighter-rouge">pip</code>, or <code class="language-plaintext highlighter-rouge">go</code> packages, but there aren’t many reusable CDK modules available in the wider community. On the other hand, there are many production-ready modules available in Terraform today.</li> <li>This is my personal opinion and I’m sure many of you will disagree with this, but I don’t buy into using programming languages for infrastructure-as-code. Although I’ve been using AWS CDK for my other projects lately, I’m still an advocate of using more limited and strict languages like YAML for infrastructure-as-code. I think “The best code is no code at all” is a good saying for infrastructure-as-code. No matter how simple a programming language is, it always brings some complexity overhead. With HCL or YAML, there is not much of a major room for any runtime upgrades or weird runtime errors or any unintended behaviours: <ul> <li>You need knowledge to write good code in a programming language and you need to replenish your knowledge occassionally because programming languages evolve continuously</li> <li>Programming language versions have an expiry date, and that means you will need to perform maintenance when the programming language’s new versions have breaking changes. You need to own the maintenance for any runtime environment major upgrades.</li> </ul> </li> </ol> <p>Third is an opinion and we could have lived with the first drawback, but the second one is the deal breaker. We’re quite limited on resources (people and time), and we can’t maintain 1000s of lines of infrastructure-as-code just to reinvent the wheel.</p> <p>An alternative for the second challenge could be “CDK for Terraform”, but we are not comfortable with living on the cutting edge as CDKTF “may still have breaking changes before its 1.0 release”.</p> <p>We could also investigate <a href="https://www.pulumi.com/docs/concepts/vs/terraform/">Pulumi</a>. Its features appear to be very promising, but Terraform’s de-facto position within the wider community, is still the tiebreaker for us. With Terraform we have a limitless number of reusable modules available, and not to mention that our existing Terraform knowledge helped our delivery rate in early days.</p> <hr/> <p>Obviously, Terraform would not be good enough on its own for software development and testing on our local workstations, so we started experimenting with a hybrid-solution to get the best out of two different worlds:</p> <ul> <li>We use Terraform to build and manage our workloads’ infra base</li> <li>We use AWS SAM to <strong>build and package but <em>not to deploy</em></strong> our serverless applications</li> <li>We wrap SAM projects into isolated Terraform states, which have only one Terraform resource, and that is an <a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/cloudformation_stack"><code class="language-plaintext highlighter-rouge">aws_cloudformation_stack</code></a></li> <li>We use <a href="https://developer.hashicorp.com/terraform/language/state/remote-state-data"><code class="language-plaintext highlighter-rouge">terraform_remote_state</code></a> to access workload infra base outputs and pass their values to the underlying CloudFormation stack through CloudFormation parameters</li> </ul> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01-480.webp 480w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01-800.webp 800w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-01.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02-480.webp 480w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02-800.webp 800w,/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/2024-07-01-how-to-startup-with-devops-part-1/diagram-02.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <div class="caption"> Swipe left to see how our pipelines work in our hybrid solution. </div> <p>Thanks to trunk-based development, strict conventional commits and automated semantic versioning, our builds produce immutable builds that we build once and deploy many. CD pipelines understand the target environment from the artefact version and perform Terraform plan &amp; apply, which does CloudFormation stack create/update in the background.</p> <p>Finally, if the Workload Infra Base gets very big, we can segregate into 2 or more repositories and orchestrate their delivery using <a href="https://terragrunt.gruntwork.io/">Terragrunt</a>.</p> <p>We were quite happy with our experiment and decided to follow this pattern in building SaaS at Xecuta. I understand our approach may seem too complex or unnecessary for some, but again, best out of two worlds:</p> <ul> <li>Thanks to Terraform, we can reuse terraform modules produced by the community and/or build our own private modules, resulting in low and modular LoC for our infrastructure-as-code</li> <li>Thanks to AWS SAM, we can develop serverless applications and test them locally</li> <li>We can still manage inter-workload and intra-workload dependencies in a consistent and reliable way</li> </ul> <p>I hope you enjoyed my first blog post about Workload Infra Base pattern with hybrid implementation using AWs SAM and Terraform.</p> <p>Part 2 of this series will continue with which SCM and Orchestration tool(s) we opted to use and how we built our Shared Services initially.</p>]]></content><author><name></name></author><category term="startup"/><category term="devops"/><category term="day0"/><category term="aws"/><category term="terraform"/><category term="cdk"/><category term="aws-cdk"/><summary type="html"><![CDATA[This blog series aim to stop you delaying DevOps for your new startup. In the first section, I'm going to talk about which DevOps services and tools we use at Xecuta and later a simple shared services account architecture that serve us in our early days.]]></summary></entry></feed>